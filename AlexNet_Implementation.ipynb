{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iKQ_hrpmywrU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T19:48:59.177695Z",
          "iopub.status.busy": "2024-06-10T19:48:59.177349Z",
          "iopub.status.idle": "2024-06-10T20:13:36.070973Z",
          "shell.execute_reply": "2024-06-10T20:13:36.0699Z",
          "shell.execute_reply.started": "2024-06-10T19:48:59.177669Z"
        },
        "id": "Jj3X-iznywrV",
        "outputId": "6e41a0c8-da28-45e8-cc54-12caa95e7a31",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0/49, Loss: 2.3020, Train Acc: 0.1013, Val Acc: 0.1241\n",
            "Epoch 1/49, Loss: 2.2509, Train Acc: 0.1383, Val Acc: 0.2469\n",
            "Epoch 2/49, Loss: 2.2017, Train Acc: 0.1648, Val Acc: 0.2653\n",
            "Epoch 3/49, Loss: 2.1680, Train Acc: 0.1700, Val Acc: 0.2515\n",
            "Epoch 4/49, Loss: 2.1465, Train Acc: 0.1792, Val Acc: 0.2807\n",
            "Epoch 5/49, Loss: 2.1225, Train Acc: 0.1920, Val Acc: 0.2997\n",
            "Epoch 6/49, Loss: 2.1065, Train Acc: 0.1972, Val Acc: 0.3308\n",
            "Epoch 7/49, Loss: 2.1001, Train Acc: 0.2006, Val Acc: 0.3030\n",
            "Epoch 8/49, Loss: 2.0918, Train Acc: 0.2085, Val Acc: 0.2819\n",
            "Epoch 9/49, Loss: 2.0788, Train Acc: 0.2132, Val Acc: 0.2734\n",
            "Epoch 10/49, Loss: 2.0729, Train Acc: 0.2141, Val Acc: 0.3012\n",
            "Epoch 11/49, Loss: 2.0591, Train Acc: 0.2226, Val Acc: 0.3389\n",
            "Epoch 12/49, Loss: 2.0465, Train Acc: 0.2241, Val Acc: 0.3690\n",
            "Epoch 13/49, Loss: 2.0427, Train Acc: 0.2275, Val Acc: 0.3542\n",
            "Epoch 14/49, Loss: 2.0382, Train Acc: 0.2277, Val Acc: 0.3446\n",
            "Epoch 15/49, Loss: 2.0200, Train Acc: 0.2354, Val Acc: 0.3529\n",
            "Epoch 16/49, Loss: 2.0150, Train Acc: 0.2402, Val Acc: 0.3764\n",
            "Epoch 17/49, Loss: 2.0058, Train Acc: 0.2402, Val Acc: 0.4195\n",
            "Epoch 18/49, Loss: 1.9976, Train Acc: 0.2451, Val Acc: 0.4017\n",
            "Epoch 19/49, Loss: 1.9902, Train Acc: 0.2503, Val Acc: 0.4591\n",
            "Epoch 20/49, Loss: 1.9773, Train Acc: 0.2558, Val Acc: 0.4891\n",
            "Epoch 21/49, Loss: 1.9684, Train Acc: 0.2583, Val Acc: 0.4437\n",
            "Epoch 22/49, Loss: 1.9665, Train Acc: 0.2602, Val Acc: 0.4668\n",
            "Epoch 23/49, Loss: 1.9615, Train Acc: 0.2592, Val Acc: 0.4838\n",
            "Epoch 24/49, Loss: 1.9580, Train Acc: 0.2621, Val Acc: 0.4581\n",
            "Epoch 25/49, Loss: 1.9495, Train Acc: 0.2654, Val Acc: 0.5103\n",
            "Epoch 26/49, Loss: 1.9439, Train Acc: 0.2658, Val Acc: 0.4948\n",
            "Epoch 27/49, Loss: 1.9356, Train Acc: 0.2706, Val Acc: 0.4977\n",
            "Epoch 28/49, Loss: 1.9305, Train Acc: 0.2736, Val Acc: 0.5172\n",
            "Epoch 29/49, Loss: 1.9267, Train Acc: 0.2745, Val Acc: 0.5659\n",
            "Epoch 30/49, Loss: 1.9166, Train Acc: 0.2751, Val Acc: 0.5566\n",
            "Epoch 31/49, Loss: 1.9129, Train Acc: 0.2796, Val Acc: 0.5523\n",
            "Epoch 32/49, Loss: 1.9116, Train Acc: 0.2806, Val Acc: 0.5923\n",
            "Epoch 33/49, Loss: 1.9044, Train Acc: 0.2849, Val Acc: 0.5748\n",
            "Epoch 34/49, Loss: 1.9011, Train Acc: 0.2830, Val Acc: 0.5692\n",
            "Epoch 35/49, Loss: 1.8926, Train Acc: 0.2904, Val Acc: 0.5608\n",
            "Epoch 36/49, Loss: 1.8925, Train Acc: 0.2889, Val Acc: 0.5384\n",
            "Epoch 37/49, Loss: 1.8860, Train Acc: 0.2903, Val Acc: 0.5582\n",
            "Epoch 38/49, Loss: 1.8863, Train Acc: 0.2895, Val Acc: 0.5724\n",
            "Epoch 39/49, Loss: 1.8855, Train Acc: 0.2916, Val Acc: 0.5764\n",
            "Epoch 40/49, Loss: 1.8825, Train Acc: 0.2918, Val Acc: 0.5700\n",
            "Epoch 41/49, Loss: 1.8759, Train Acc: 0.2965, Val Acc: 0.5993\n",
            "Epoch 42/49, Loss: 1.8752, Train Acc: 0.2959, Val Acc: 0.5922\n",
            "Epoch 43/49, Loss: 1.8752, Train Acc: 0.2939, Val Acc: 0.5472\n",
            "Epoch 44/49, Loss: 1.8671, Train Acc: 0.2977, Val Acc: 0.5972\n",
            "Epoch 45/49, Loss: 1.8626, Train Acc: 0.2980, Val Acc: 0.5972\n",
            "Epoch 46/49, Loss: 1.8689, Train Acc: 0.2958, Val Acc: 0.5884\n",
            "Epoch 47/49, Loss: 1.8664, Train Acc: 0.2998, Val Acc: 0.6258\n",
            "Epoch 48/49, Loss: 1.8540, Train Acc: 0.3057, Val Acc: 0.6025\n",
            "Epoch 49/49, Loss: 1.8624, Train Acc: 0.2997, Val Acc: 0.6181\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torchvision.transforms import Lambda\n",
        "\n",
        "# Define AlexNet adapted for CIFAR-10/CIFAR-100\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 4 * 4, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# PCA Color Augmentation\n",
        "def pca_color_augmentation(image):\n",
        "    reshaped_image = image.reshape(-1, 3).astype(np.float32)\n",
        "    mean = np.mean(reshaped_image, axis=0)\n",
        "    std = np.std(reshaped_image, axis=0)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    std[std == 0] = 1\n",
        "\n",
        "    normalized_image = (reshaped_image - mean) / std\n",
        "\n",
        "    cov_matrix = np.cov(normalized_image, rowvar=False)\n",
        "\n",
        "    # Add a small value to the diagonal for numerical stability\n",
        "    cov_matrix += np.eye(cov_matrix.shape[0]) * 1e-5\n",
        "\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvectors = eigenvectors[:, sorted_indices]\n",
        "    eigenvalues = eigenvalues[sorted_indices]\n",
        "\n",
        "    alphas = np.random.normal(0, 0.1, 3)\n",
        "    pca_jitter = np.dot(eigenvectors, alphas * eigenvalues)\n",
        "    pca_jitter = (pca_jitter * std + mean).astype(np.float32)\n",
        "    augmented_image = normalized_image + pca_jitter\n",
        "    augmented_image = (augmented_image * std + mean).astype(np.uint8)\n",
        "\n",
        "    return augmented_image.reshape(image.shape)\n",
        "\n",
        "\n",
        "# Transforms including PCA color augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    Lambda(lambda x: torch.tensor(pca_color_augmentation(x.numpy().transpose((1, 2, 0))), dtype=torch.float32).permute(2, 0, 1)),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 or CIFAR-100\n",
        "def get_dataloaders(dataset='CIFAR10', batch_size=128):\n",
        "    if dataset == 'CIFAR10':\n",
        "        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "        num_classes = 10\n",
        "    elif dataset == 'CIFAR100':\n",
        "        train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transforms)\n",
        "        test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transforms)\n",
        "        num_classes = 100\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return train_loader, test_loader, num_classes\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=25, device='cuda'):\n",
        "    model.to(device)\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_corrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_acc = val_running_corrects.double() / len(test_loader.dataset)\n",
        "        print(f'Epoch {epoch}/{num_epochs-1}, Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Define dataset and dataloaders\n",
        "train_loader, test_loader, num_classes = get_dataloaders(dataset='CIFAR10', batch_size=128)\n",
        "\n",
        "# Initialize model, loss function, optimizer, and scheduler\n",
        "model = AlexNet(num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True, eps=1e-8)\n",
        "\n",
        "# Train the model\n",
        "trained_model = train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=50)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T21:08:09.715928Z",
          "iopub.status.busy": "2024-06-10T21:08:09.715593Z",
          "iopub.status.idle": "2024-06-10T21:57:59.385014Z",
          "shell.execute_reply": "2024-06-10T21:57:59.383869Z",
          "shell.execute_reply.started": "2024-06-10T21:08:09.715901Z"
        },
        "id": "v7ZJAv-mywrZ",
        "outputId": "1deceac3-8346-41d9-f519-0f9eed395dbb",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0/99, Loss: 2.3016, Train Acc: 0.1043, Val Acc: 0.1086\n",
            "Epoch 1/99, Loss: 2.2461, Train Acc: 0.1433, Val Acc: 0.2405\n",
            "Epoch 2/99, Loss: 2.2090, Train Acc: 0.1626, Val Acc: 0.2754\n",
            "Epoch 3/99, Loss: 2.1720, Train Acc: 0.1708, Val Acc: 0.2842\n",
            "Epoch 4/99, Loss: 2.1483, Train Acc: 0.1802, Val Acc: 0.2679\n",
            "Epoch 5/99, Loss: 2.1261, Train Acc: 0.1902, Val Acc: 0.2903\n",
            "Epoch 6/99, Loss: 2.1074, Train Acc: 0.1997, Val Acc: 0.3355\n",
            "Epoch 7/99, Loss: 2.0979, Train Acc: 0.1992, Val Acc: 0.2601\n",
            "Epoch 8/99, Loss: 2.0824, Train Acc: 0.2104, Val Acc: 0.3071\n",
            "Epoch 9/99, Loss: 2.0802, Train Acc: 0.2103, Val Acc: 0.3357\n",
            "Epoch 10/99, Loss: 2.0730, Train Acc: 0.2128, Val Acc: 0.3113\n",
            "Epoch 11/99, Loss: 2.0594, Train Acc: 0.2221, Val Acc: 0.3295\n",
            "Epoch 12/99, Loss: 2.0529, Train Acc: 0.2247, Val Acc: 0.3317\n",
            "Epoch 13/99, Loss: 2.0415, Train Acc: 0.2273, Val Acc: 0.4017\n",
            "Epoch 14/99, Loss: 2.0376, Train Acc: 0.2273, Val Acc: 0.3661\n",
            "Epoch 15/99, Loss: 2.0210, Train Acc: 0.2343, Val Acc: 0.3721\n",
            "Epoch 16/99, Loss: 2.0135, Train Acc: 0.2396, Val Acc: 0.4366\n",
            "Epoch 17/99, Loss: 2.0052, Train Acc: 0.2446, Val Acc: 0.4419\n",
            "Epoch 18/99, Loss: 1.9985, Train Acc: 0.2463, Val Acc: 0.4284\n",
            "Epoch 19/99, Loss: 1.9939, Train Acc: 0.2510, Val Acc: 0.4653\n",
            "Epoch 20/99, Loss: 1.9859, Train Acc: 0.2515, Val Acc: 0.4865\n",
            "Epoch 21/99, Loss: 1.9726, Train Acc: 0.2572, Val Acc: 0.4786\n",
            "Epoch 22/99, Loss: 1.9705, Train Acc: 0.2574, Val Acc: 0.4575\n",
            "Epoch 23/99, Loss: 1.9611, Train Acc: 0.2619, Val Acc: 0.4589\n",
            "Epoch 24/99, Loss: 1.9587, Train Acc: 0.2620, Val Acc: 0.4721\n",
            "Epoch 25/99, Loss: 1.9475, Train Acc: 0.2673, Val Acc: 0.4964\n",
            "Epoch 26/99, Loss: 1.9408, Train Acc: 0.2689, Val Acc: 0.4907\n",
            "Epoch 27/99, Loss: 1.9354, Train Acc: 0.2714, Val Acc: 0.4968\n",
            "Epoch 28/99, Loss: 1.9203, Train Acc: 0.2754, Val Acc: 0.5383\n",
            "Epoch 29/99, Loss: 1.9265, Train Acc: 0.2757, Val Acc: 0.5235\n",
            "Epoch 30/99, Loss: 1.9155, Train Acc: 0.2790, Val Acc: 0.5705\n",
            "Epoch 31/99, Loss: 1.9043, Train Acc: 0.2836, Val Acc: 0.5451\n",
            "Epoch 32/99, Loss: 1.9053, Train Acc: 0.2817, Val Acc: 0.5296\n",
            "Epoch 33/99, Loss: 1.9055, Train Acc: 0.2821, Val Acc: 0.5835\n",
            "Epoch 34/99, Loss: 1.8957, Train Acc: 0.2868, Val Acc: 0.5470\n",
            "Epoch 35/99, Loss: 1.8937, Train Acc: 0.2876, Val Acc: 0.5765\n",
            "Epoch 36/99, Loss: 1.8916, Train Acc: 0.2899, Val Acc: 0.5475\n",
            "Epoch 37/99, Loss: 1.8810, Train Acc: 0.2920, Val Acc: 0.5905\n",
            "Epoch 38/99, Loss: 1.8864, Train Acc: 0.2916, Val Acc: 0.5648\n",
            "Epoch 39/99, Loss: 1.8791, Train Acc: 0.2918, Val Acc: 0.5843\n",
            "Epoch 40/99, Loss: 1.8714, Train Acc: 0.2982, Val Acc: 0.5877\n",
            "Epoch 41/99, Loss: 1.8751, Train Acc: 0.2938, Val Acc: 0.5732\n",
            "Epoch 42/99, Loss: 1.8641, Train Acc: 0.2976, Val Acc: 0.5920\n",
            "Epoch 43/99, Loss: 1.8635, Train Acc: 0.2972, Val Acc: 0.5909\n",
            "Epoch 44/99, Loss: 1.8600, Train Acc: 0.3015, Val Acc: 0.5740\n",
            "Epoch 45/99, Loss: 1.8628, Train Acc: 0.3015, Val Acc: 0.5782\n",
            "Epoch 46/99, Loss: 1.8651, Train Acc: 0.3008, Val Acc: 0.5955\n",
            "Epoch 47/99, Loss: 1.8523, Train Acc: 0.3043, Val Acc: 0.5896\n",
            "Epoch 48/99, Loss: 1.8527, Train Acc: 0.3040, Val Acc: 0.5935\n",
            "Epoch 49/99, Loss: 1.8568, Train Acc: 0.3026, Val Acc: 0.6395\n",
            "Epoch 50/99, Loss: 1.8540, Train Acc: 0.3041, Val Acc: 0.5915\n",
            "Epoch 51/99, Loss: 1.8495, Train Acc: 0.3049, Val Acc: 0.5810\n",
            "Epoch 52/99, Loss: 1.8468, Train Acc: 0.3067, Val Acc: 0.5993\n",
            "Epoch 53/99, Loss: 1.8401, Train Acc: 0.3072, Val Acc: 0.5980\n",
            "Epoch 54/99, Loss: 1.8462, Train Acc: 0.3063, Val Acc: 0.5446\n",
            "Epoch 55/99, Loss: 1.8393, Train Acc: 0.3102, Val Acc: 0.6286\n",
            "Epoch 56/99, Loss: 1.8397, Train Acc: 0.3079, Val Acc: 0.6207\n",
            "Epoch 57/99, Loss: 1.8351, Train Acc: 0.3087, Val Acc: 0.5857\n",
            "Epoch 58/99, Loss: 1.8364, Train Acc: 0.3098, Val Acc: 0.6128\n",
            "Epoch 59/99, Loss: 1.8310, Train Acc: 0.3104, Val Acc: 0.5848\n",
            "Epoch 60/99, Loss: 1.8343, Train Acc: 0.3104, Val Acc: 0.5965\n",
            "Epoch 00061: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 61/99, Loss: 1.8093, Train Acc: 0.3192, Val Acc: 0.6421\n",
            "Epoch 62/99, Loss: 1.8053, Train Acc: 0.3217, Val Acc: 0.6467\n",
            "Epoch 63/99, Loss: 1.7916, Train Acc: 0.3253, Val Acc: 0.6431\n",
            "Epoch 64/99, Loss: 1.7843, Train Acc: 0.3298, Val Acc: 0.6365\n",
            "Epoch 65/99, Loss: 1.8005, Train Acc: 0.3206, Val Acc: 0.6394\n",
            "Epoch 66/99, Loss: 1.7938, Train Acc: 0.3264, Val Acc: 0.6434\n",
            "Epoch 67/99, Loss: 1.7900, Train Acc: 0.3270, Val Acc: 0.6367\n",
            "Epoch 68/99, Loss: 1.7866, Train Acc: 0.3289, Val Acc: 0.6478\n",
            "Epoch 69/99, Loss: 1.7928, Train Acc: 0.3250, Val Acc: 0.6510\n",
            "Epoch 70/99, Loss: 1.7919, Train Acc: 0.3288, Val Acc: 0.6527\n",
            "Epoch 71/99, Loss: 1.7848, Train Acc: 0.3295, Val Acc: 0.6468\n",
            "Epoch 72/99, Loss: 1.7912, Train Acc: 0.3254, Val Acc: 0.6405\n",
            "Epoch 73/99, Loss: 1.7809, Train Acc: 0.3299, Val Acc: 0.6456\n",
            "Epoch 74/99, Loss: 1.7832, Train Acc: 0.3288, Val Acc: 0.6461\n",
            "Epoch 75/99, Loss: 1.7868, Train Acc: 0.3275, Val Acc: 0.6528\n",
            "Epoch 76/99, Loss: 1.7853, Train Acc: 0.3304, Val Acc: 0.6479\n",
            "Epoch 77/99, Loss: 1.7856, Train Acc: 0.3302, Val Acc: 0.6577\n",
            "Epoch 78/99, Loss: 1.7812, Train Acc: 0.3294, Val Acc: 0.6459\n",
            "Epoch 79/99, Loss: 1.7825, Train Acc: 0.3303, Val Acc: 0.6553\n",
            "Epoch 80/99, Loss: 1.7837, Train Acc: 0.3311, Val Acc: 0.6563\n",
            "Epoch 81/99, Loss: 1.7855, Train Acc: 0.3290, Val Acc: 0.6537\n",
            "Epoch 82/99, Loss: 1.7803, Train Acc: 0.3309, Val Acc: 0.6524\n",
            "Epoch 83/99, Loss: 1.7778, Train Acc: 0.3319, Val Acc: 0.6456\n",
            "Epoch 84/99, Loss: 1.7798, Train Acc: 0.3305, Val Acc: 0.6521\n",
            "Epoch 85/99, Loss: 1.7820, Train Acc: 0.3302, Val Acc: 0.6634\n",
            "Epoch 86/99, Loss: 1.7778, Train Acc: 0.3326, Val Acc: 0.6619\n",
            "Epoch 87/99, Loss: 1.7778, Train Acc: 0.3311, Val Acc: 0.6621\n",
            "Epoch 88/99, Loss: 1.7765, Train Acc: 0.3317, Val Acc: 0.6642\n",
            "Epoch 89/99, Loss: 1.7786, Train Acc: 0.3338, Val Acc: 0.6692\n",
            "Epoch 90/99, Loss: 1.7803, Train Acc: 0.3285, Val Acc: 0.6561\n",
            "Epoch 91/99, Loss: 1.7802, Train Acc: 0.3292, Val Acc: 0.6554\n",
            "Epoch 92/99, Loss: 1.7763, Train Acc: 0.3292, Val Acc: 0.6498\n",
            "Epoch 93/99, Loss: 1.7793, Train Acc: 0.3297, Val Acc: 0.6656\n",
            "Epoch 94/99, Loss: 1.7785, Train Acc: 0.3318, Val Acc: 0.6586\n",
            "Epoch 95/99, Loss: 1.7808, Train Acc: 0.3291, Val Acc: 0.6631\n",
            "Epoch 96/99, Loss: 1.7800, Train Acc: 0.3301, Val Acc: 0.6670\n",
            "Epoch 97/99, Loss: 1.7807, Train Acc: 0.3323, Val Acc: 0.6669\n",
            "Epoch 98/99, Loss: 1.7697, Train Acc: 0.3367, Val Acc: 0.6686\n",
            "Epoch 99/99, Loss: 1.7707, Train Acc: 0.3348, Val Acc: 0.6635\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torchvision.transforms import Lambda\n",
        "\n",
        "# Define AlexNet adapted for CIFAR-10/CIFAR-100\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 4 * 4, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# PCA Color Augmentation\n",
        "def pca_color_augmentation(image):\n",
        "    reshaped_image = image.reshape(-1, 3).astype(np.float32)\n",
        "    mean = np.mean(reshaped_image, axis=0)\n",
        "    std = np.std(reshaped_image, axis=0)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    std[std == 0] = 1\n",
        "\n",
        "    normalized_image = (reshaped_image - mean) / std\n",
        "\n",
        "    cov_matrix = np.cov(normalized_image, rowvar=False)\n",
        "\n",
        "    # Add a small value to the diagonal for numerical stability\n",
        "    cov_matrix += np.eye(cov_matrix.shape[0]) * 1e-5\n",
        "\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvectors = eigenvectors[:, sorted_indices]\n",
        "    eigenvalues = eigenvalues[sorted_indices]\n",
        "\n",
        "    alphas = np.random.normal(0, 0.1, 3)\n",
        "    pca_jitter = np.dot(eigenvectors, alphas * eigenvalues)\n",
        "    pca_jitter = (pca_jitter * std + mean).astype(np.float32)\n",
        "    augmented_image = normalized_image + pca_jitter\n",
        "    augmented_image = (augmented_image * std + mean).astype(np.uint8)\n",
        "\n",
        "    return augmented_image.reshape(image.shape)\n",
        "\n",
        "\n",
        "# Transforms including PCA color augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), #40x40 pixels before the crop.\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    Lambda(lambda x: torch.tensor(pca_color_augmentation(x.numpy().transpose((1, 2, 0))), dtype=torch.float32).permute(2, 0, 1)),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 or CIFAR-100\n",
        "def get_dataloaders(dataset='CIFAR10', batch_size=128):\n",
        "    if dataset == 'CIFAR10':\n",
        "        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "        num_classes = 10\n",
        "    elif dataset == 'CIFAR100':\n",
        "        train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transforms)\n",
        "        test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transforms)\n",
        "        num_classes = 100\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return train_loader, test_loader, num_classes\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=25, device='cuda'):\n",
        "    model.to(device)\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_corrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_acc = val_running_corrects.double() / len(test_loader.dataset)\n",
        "        print(f'Epoch {epoch}/{num_epochs-1}, Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# Define dataset and dataloaders\n",
        "train_loader, test_loader, num_classes = get_dataloaders(dataset='CIFAR10', batch_size=128)\n",
        "\n",
        "# Initialize model, loss function, optimizer, and scheduler\n",
        "model = AlexNet(num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True, eps=1e-8)\n",
        "\n",
        "# Train the model\n",
        "trained_model = train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AUauGgV1ywrZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "680fJh0Eywra"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "th8NpB83ywra"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TK6iJcTUywra"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x23GWQdUywra"
      },
      "source": [
        "THIS CODE with PCA!!!!!!!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-11T10:48:57.753893Z",
          "iopub.status.busy": "2024-06-11T10:48:57.753445Z",
          "iopub.status.idle": "2024-06-11T11:56:38.342424Z",
          "shell.execute_reply": "2024-06-11T11:56:38.341362Z",
          "shell.execute_reply.started": "2024-06-11T10:48:57.753853Z"
        },
        "id": "p0JS5FVuywrb",
        "outputId": "f5e04375-357d-45ed-bb39-a7b984edd1db",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 0/199, Loss: 2.1717, Train Acc: 0.1816, Val Acc: 0.2303\n",
            "Epoch 1/199, Loss: 2.0734, Train Acc: 0.2304, Val Acc: 0.2533\n",
            "Epoch 2/199, Loss: 2.0337, Train Acc: 0.2452, Val Acc: 0.3066\n",
            "Epoch 3/199, Loss: 2.0061, Train Acc: 0.2604, Val Acc: 0.2737\n",
            "Epoch 4/199, Loss: 1.9886, Train Acc: 0.2680, Val Acc: 0.3126\n",
            "Epoch 5/199, Loss: 1.9701, Train Acc: 0.2766, Val Acc: 0.3234\n",
            "Epoch 6/199, Loss: 1.9514, Train Acc: 0.2856, Val Acc: 0.2916\n",
            "Epoch 7/199, Loss: 1.9374, Train Acc: 0.2898, Val Acc: 0.3341\n",
            "Epoch 8/199, Loss: 1.9244, Train Acc: 0.2971, Val Acc: 0.2929\n",
            "Epoch 9/199, Loss: 1.9140, Train Acc: 0.2995, Val Acc: 0.4025\n",
            "Epoch 10/199, Loss: 1.9022, Train Acc: 0.3033, Val Acc: 0.3387\n",
            "Epoch 11/199, Loss: 1.8913, Train Acc: 0.3103, Val Acc: 0.3114\n",
            "Epoch 12/199, Loss: 1.8822, Train Acc: 0.3132, Val Acc: 0.3612\n",
            "Epoch 13/199, Loss: 1.8718, Train Acc: 0.3185, Val Acc: 0.3750\n",
            "Epoch 14/199, Loss: 1.8626, Train Acc: 0.3221, Val Acc: 0.3372\n",
            "Epoch 15/199, Loss: 1.8876, Train Acc: 0.3134, Val Acc: 0.2790\n",
            "Epoch 16/199, Loss: 1.8667, Train Acc: 0.3226, Val Acc: 0.3875\n",
            "Epoch 17/199, Loss: 1.8562, Train Acc: 0.3240, Val Acc: 0.3970\n",
            "Epoch 18/199, Loss: 1.8473, Train Acc: 0.3295, Val Acc: 0.3967\n",
            "Epoch 19/199, Loss: 1.8435, Train Acc: 0.3290, Val Acc: 0.3464\n",
            "Epoch 20/199, Loss: 1.8339, Train Acc: 0.3341, Val Acc: 0.4018\n",
            "Epoch 00021: reducing learning rate of group 0 to 1.0000e-02.\n",
            "Epoch 21/199, Loss: 1.7356, Train Acc: 0.3712, Val Acc: 0.4719\n",
            "Epoch 22/199, Loss: 1.7098, Train Acc: 0.3774, Val Acc: 0.4807\n",
            "Epoch 23/199, Loss: 1.6993, Train Acc: 0.3840, Val Acc: 0.4733\n",
            "Epoch 24/199, Loss: 1.6899, Train Acc: 0.3875, Val Acc: 0.4851\n",
            "Epoch 25/199, Loss: 1.6816, Train Acc: 0.3870, Val Acc: 0.4787\n",
            "Epoch 26/199, Loss: 1.6774, Train Acc: 0.3899, Val Acc: 0.4884\n",
            "Epoch 27/199, Loss: 1.6706, Train Acc: 0.3933, Val Acc: 0.5058\n",
            "Epoch 28/199, Loss: 1.6674, Train Acc: 0.3931, Val Acc: 0.4989\n",
            "Epoch 29/199, Loss: 1.6606, Train Acc: 0.3973, Val Acc: 0.4833\n",
            "Epoch 30/199, Loss: 1.6548, Train Acc: 0.3979, Val Acc: 0.5186\n",
            "Epoch 31/199, Loss: 1.6528, Train Acc: 0.3985, Val Acc: 0.4783\n",
            "Epoch 32/199, Loss: 1.6535, Train Acc: 0.3996, Val Acc: 0.5215\n",
            "Epoch 33/199, Loss: 1.6496, Train Acc: 0.4030, Val Acc: 0.5055\n",
            "Epoch 34/199, Loss: 1.6433, Train Acc: 0.4012, Val Acc: 0.5117\n",
            "Epoch 35/199, Loss: 1.6369, Train Acc: 0.4032, Val Acc: 0.5100\n",
            "Epoch 36/199, Loss: 1.6372, Train Acc: 0.4033, Val Acc: 0.4851\n",
            "Epoch 37/199, Loss: 1.6332, Train Acc: 0.4061, Val Acc: 0.5189\n",
            "Epoch 38/199, Loss: 1.6287, Train Acc: 0.4094, Val Acc: 0.4617\n",
            "Epoch 39/199, Loss: 1.6307, Train Acc: 0.4072, Val Acc: 0.5359\n",
            "Epoch 40/199, Loss: 1.6210, Train Acc: 0.4092, Val Acc: 0.5181\n",
            "Epoch 41/199, Loss: 1.6206, Train Acc: 0.4127, Val Acc: 0.5248\n",
            "Epoch 42/199, Loss: 1.6197, Train Acc: 0.4122, Val Acc: 0.5283\n",
            "Epoch 43/199, Loss: 1.6177, Train Acc: 0.4120, Val Acc: 0.5241\n",
            "Epoch 44/199, Loss: 1.6149, Train Acc: 0.4155, Val Acc: 0.5336\n",
            "Epoch 45/199, Loss: 1.6135, Train Acc: 0.4115, Val Acc: 0.5027\n",
            "Epoch 46/199, Loss: 1.6098, Train Acc: 0.4145, Val Acc: 0.5149\n",
            "Epoch 47/199, Loss: 1.6074, Train Acc: 0.4151, Val Acc: 0.4999\n",
            "Epoch 48/199, Loss: 1.6034, Train Acc: 0.4177, Val Acc: 0.5223\n",
            "Epoch 49/199, Loss: 1.5982, Train Acc: 0.4209, Val Acc: 0.4888\n",
            "Epoch 50/199, Loss: 1.5994, Train Acc: 0.4176, Val Acc: 0.4821\n",
            "Epoch 00051: reducing learning rate of group 0 to 1.0000e-03.\n",
            "Epoch 51/199, Loss: 1.5624, Train Acc: 0.4336, Val Acc: 0.5211\n",
            "Epoch 52/199, Loss: 1.5547, Train Acc: 0.4349, Val Acc: 0.5200\n",
            "Epoch 53/199, Loss: 1.5568, Train Acc: 0.4363, Val Acc: 0.5192\n",
            "Epoch 54/199, Loss: 1.5451, Train Acc: 0.4371, Val Acc: 0.5322\n",
            "Epoch 55/199, Loss: 1.5494, Train Acc: 0.4387, Val Acc: 0.5358\n",
            "Epoch 56/199, Loss: 1.5409, Train Acc: 0.4403, Val Acc: 0.5359\n",
            "Epoch 57/199, Loss: 1.5423, Train Acc: 0.4409, Val Acc: 0.5332\n",
            "Epoch 58/199, Loss: 1.5383, Train Acc: 0.4399, Val Acc: 0.5348\n",
            "Epoch 59/199, Loss: 1.5350, Train Acc: 0.4433, Val Acc: 0.5451\n",
            "Epoch 60/199, Loss: 1.5367, Train Acc: 0.4418, Val Acc: 0.5336\n",
            "Epoch 61/199, Loss: 1.5374, Train Acc: 0.4415, Val Acc: 0.5294\n",
            "Epoch 62/199, Loss: 1.5328, Train Acc: 0.4446, Val Acc: 0.5354\n",
            "Epoch 63/199, Loss: 1.5339, Train Acc: 0.4425, Val Acc: 0.5415\n",
            "Epoch 64/199, Loss: 1.5291, Train Acc: 0.4425, Val Acc: 0.5348\n",
            "Epoch 65/199, Loss: 1.5299, Train Acc: 0.4453, Val Acc: 0.5425\n",
            "Epoch 66/199, Loss: 1.5303, Train Acc: 0.4442, Val Acc: 0.5529\n",
            "Epoch 67/199, Loss: 1.5283, Train Acc: 0.4454, Val Acc: 0.5370\n",
            "Epoch 68/199, Loss: 1.5294, Train Acc: 0.4464, Val Acc: 0.5223\n",
            "Epoch 69/199, Loss: 1.5254, Train Acc: 0.4456, Val Acc: 0.5305\n",
            "Epoch 70/199, Loss: 1.5238, Train Acc: 0.4493, Val Acc: 0.5323\n",
            "Epoch 71/199, Loss: 1.5230, Train Acc: 0.4452, Val Acc: 0.5291\n",
            "Epoch 72/199, Loss: 1.5205, Train Acc: 0.4491, Val Acc: 0.5357\n",
            "Epoch 73/199, Loss: 1.5213, Train Acc: 0.4473, Val Acc: 0.5242\n",
            "Epoch 74/199, Loss: 1.5201, Train Acc: 0.4484, Val Acc: 0.5302\n",
            "Epoch 75/199, Loss: 1.5147, Train Acc: 0.4510, Val Acc: 0.5238\n",
            "Epoch 76/199, Loss: 1.5188, Train Acc: 0.4494, Val Acc: 0.5330\n",
            "Epoch 77/199, Loss: 1.5140, Train Acc: 0.4491, Val Acc: 0.5425\n",
            "Epoch 00078: reducing learning rate of group 0 to 1.0000e-04.\n",
            "Epoch 78/199, Loss: 1.5125, Train Acc: 0.4507, Val Acc: 0.5367\n",
            "Epoch 79/199, Loss: 1.5079, Train Acc: 0.4516, Val Acc: 0.5373\n",
            "Epoch 80/199, Loss: 1.5065, Train Acc: 0.4506, Val Acc: 0.5369\n",
            "Epoch 81/199, Loss: 1.5097, Train Acc: 0.4509, Val Acc: 0.5366\n",
            "Epoch 82/199, Loss: 1.5067, Train Acc: 0.4521, Val Acc: 0.5347\n",
            "Epoch 83/199, Loss: 1.5062, Train Acc: 0.4527, Val Acc: 0.5385\n",
            "Epoch 84/199, Loss: 1.5095, Train Acc: 0.4530, Val Acc: 0.5380\n",
            "Epoch 85/199, Loss: 1.5067, Train Acc: 0.4528, Val Acc: 0.5373\n",
            "Epoch 86/199, Loss: 1.5060, Train Acc: 0.4565, Val Acc: 0.5394\n",
            "Epoch 87/199, Loss: 1.5055, Train Acc: 0.4529, Val Acc: 0.5380\n",
            "Epoch 88/199, Loss: 1.5082, Train Acc: 0.4525, Val Acc: 0.5382\n",
            "Epoch 00089: reducing learning rate of group 0 to 1.0000e-05.\n",
            "Epoch 89/199, Loss: 1.5035, Train Acc: 0.4537, Val Acc: 0.5395\n",
            "Epoch 90/199, Loss: 1.5076, Train Acc: 0.4543, Val Acc: 0.5390\n",
            "Epoch 91/199, Loss: 1.5057, Train Acc: 0.4535, Val Acc: 0.5389\n",
            "Epoch 92/199, Loss: 1.5063, Train Acc: 0.4548, Val Acc: 0.5385\n",
            "Epoch 93/199, Loss: 1.5082, Train Acc: 0.4505, Val Acc: 0.5382\n",
            "Epoch 94/199, Loss: 1.5050, Train Acc: 0.4548, Val Acc: 0.5389\n",
            "Epoch 95/199, Loss: 1.5071, Train Acc: 0.4547, Val Acc: 0.5387\n",
            "Epoch 96/199, Loss: 1.5085, Train Acc: 0.4566, Val Acc: 0.5378\n",
            "Epoch 97/199, Loss: 1.5128, Train Acc: 0.4519, Val Acc: 0.5379\n",
            "Epoch 98/199, Loss: 1.5072, Train Acc: 0.4534, Val Acc: 0.5377\n",
            "Epoch 99/199, Loss: 1.5024, Train Acc: 0.4552, Val Acc: 0.5382\n",
            "Epoch 00100: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Epoch 100/199, Loss: 1.5062, Train Acc: 0.4550, Val Acc: 0.5383\n",
            "Epoch 101/199, Loss: 1.5067, Train Acc: 0.4541, Val Acc: 0.5382\n",
            "Epoch 102/199, Loss: 1.5090, Train Acc: 0.4513, Val Acc: 0.5382\n",
            "Epoch 103/199, Loss: 1.5044, Train Acc: 0.4543, Val Acc: 0.5382\n",
            "Epoch 104/199, Loss: 1.5033, Train Acc: 0.4560, Val Acc: 0.5382\n",
            "Epoch 105/199, Loss: 1.5052, Train Acc: 0.4529, Val Acc: 0.5383\n",
            "Epoch 106/199, Loss: 1.5067, Train Acc: 0.4544, Val Acc: 0.5384\n",
            "Epoch 107/199, Loss: 1.5013, Train Acc: 0.4532, Val Acc: 0.5383\n",
            "Epoch 108/199, Loss: 1.5051, Train Acc: 0.4549, Val Acc: 0.5382\n",
            "Epoch 109/199, Loss: 1.5029, Train Acc: 0.4548, Val Acc: 0.5383\n",
            "Epoch 110/199, Loss: 1.5071, Train Acc: 0.4523, Val Acc: 0.5383\n",
            "Epoch 00111: reducing learning rate of group 0 to 1.0000e-07.\n",
            "Epoch 111/199, Loss: 1.5039, Train Acc: 0.4551, Val Acc: 0.5383\n",
            "Epoch 112/199, Loss: 1.5066, Train Acc: 0.4559, Val Acc: 0.5383\n",
            "Epoch 113/199, Loss: 1.5049, Train Acc: 0.4551, Val Acc: 0.5383\n",
            "Epoch 114/199, Loss: 1.5091, Train Acc: 0.4527, Val Acc: 0.5383\n",
            "Epoch 115/199, Loss: 1.5086, Train Acc: 0.4547, Val Acc: 0.5383\n",
            "Epoch 116/199, Loss: 1.5067, Train Acc: 0.4524, Val Acc: 0.5383\n",
            "Epoch 117/199, Loss: 1.5065, Train Acc: 0.4532, Val Acc: 0.5383\n",
            "Epoch 118/199, Loss: 1.5060, Train Acc: 0.4530, Val Acc: 0.5383\n",
            "Epoch 119/199, Loss: 1.5066, Train Acc: 0.4531, Val Acc: 0.5384\n",
            "Epoch 120/199, Loss: 1.5047, Train Acc: 0.4548, Val Acc: 0.5384\n",
            "Epoch 121/199, Loss: 1.5052, Train Acc: 0.4535, Val Acc: 0.5384\n",
            "Epoch 00122: reducing learning rate of group 0 to 1.0000e-08.\n",
            "Epoch 122/199, Loss: 1.5036, Train Acc: 0.4532, Val Acc: 0.5384\n",
            "Epoch 123/199, Loss: 1.5043, Train Acc: 0.4515, Val Acc: 0.5384\n",
            "Epoch 124/199, Loss: 1.5030, Train Acc: 0.4546, Val Acc: 0.5384\n",
            "Epoch 125/199, Loss: 1.5019, Train Acc: 0.4548, Val Acc: 0.5384\n",
            "Epoch 126/199, Loss: 1.5071, Train Acc: 0.4537, Val Acc: 0.5384\n",
            "Epoch 127/199, Loss: 1.5044, Train Acc: 0.4519, Val Acc: 0.5384\n",
            "Epoch 128/199, Loss: 1.5069, Train Acc: 0.4512, Val Acc: 0.5384\n",
            "Epoch 129/199, Loss: 1.5061, Train Acc: 0.4530, Val Acc: 0.5384\n",
            "Epoch 130/199, Loss: 1.5025, Train Acc: 0.4536, Val Acc: 0.5384\n",
            "Epoch 131/199, Loss: 1.5068, Train Acc: 0.4552, Val Acc: 0.5384\n",
            "Epoch 132/199, Loss: 1.5081, Train Acc: 0.4516, Val Acc: 0.5384\n",
            "Epoch 133/199, Loss: 1.5057, Train Acc: 0.4570, Val Acc: 0.5384\n",
            "Epoch 134/199, Loss: 1.5033, Train Acc: 0.4558, Val Acc: 0.5384\n",
            "Epoch 135/199, Loss: 1.5074, Train Acc: 0.4522, Val Acc: 0.5384\n",
            "Epoch 136/199, Loss: 1.5072, Train Acc: 0.4541, Val Acc: 0.5384\n",
            "Epoch 137/199, Loss: 1.5043, Train Acc: 0.4527, Val Acc: 0.5384\n",
            "Epoch 138/199, Loss: 1.5048, Train Acc: 0.4533, Val Acc: 0.5384\n",
            "Epoch 139/199, Loss: 1.5039, Train Acc: 0.4547, Val Acc: 0.5384\n",
            "Epoch 140/199, Loss: 1.5077, Train Acc: 0.4525, Val Acc: 0.5384\n",
            "Epoch 141/199, Loss: 1.5029, Train Acc: 0.4570, Val Acc: 0.5384\n",
            "Epoch 142/199, Loss: 1.5063, Train Acc: 0.4546, Val Acc: 0.5384\n",
            "Epoch 143/199, Loss: 1.5046, Train Acc: 0.4537, Val Acc: 0.5384\n",
            "Epoch 144/199, Loss: 1.5071, Train Acc: 0.4557, Val Acc: 0.5384\n",
            "Epoch 145/199, Loss: 1.5074, Train Acc: 0.4554, Val Acc: 0.5384\n",
            "Epoch 146/199, Loss: 1.5068, Train Acc: 0.4531, Val Acc: 0.5384\n",
            "Epoch 147/199, Loss: 1.5064, Train Acc: 0.4534, Val Acc: 0.5384\n",
            "Epoch 148/199, Loss: 1.5055, Train Acc: 0.4542, Val Acc: 0.5384\n",
            "Epoch 149/199, Loss: 1.5040, Train Acc: 0.4537, Val Acc: 0.5384\n",
            "Epoch 150/199, Loss: 1.5028, Train Acc: 0.4538, Val Acc: 0.5384\n",
            "Epoch 151/199, Loss: 1.5052, Train Acc: 0.4534, Val Acc: 0.5384\n",
            "Epoch 152/199, Loss: 1.5053, Train Acc: 0.4557, Val Acc: 0.5384\n",
            "Epoch 153/199, Loss: 1.5030, Train Acc: 0.4558, Val Acc: 0.5384\n",
            "Epoch 154/199, Loss: 1.5072, Train Acc: 0.4542, Val Acc: 0.5384\n",
            "Epoch 155/199, Loss: 1.5054, Train Acc: 0.4535, Val Acc: 0.5384\n",
            "Epoch 156/199, Loss: 1.5058, Train Acc: 0.4535, Val Acc: 0.5384\n",
            "Epoch 157/199, Loss: 1.5054, Train Acc: 0.4533, Val Acc: 0.5384\n",
            "Epoch 158/199, Loss: 1.5045, Train Acc: 0.4542, Val Acc: 0.5384\n",
            "Epoch 159/199, Loss: 1.5046, Train Acc: 0.4547, Val Acc: 0.5384\n",
            "Epoch 160/199, Loss: 1.5059, Train Acc: 0.4544, Val Acc: 0.5384\n",
            "Epoch 161/199, Loss: 1.5020, Train Acc: 0.4535, Val Acc: 0.5384\n",
            "Epoch 162/199, Loss: 1.5071, Train Acc: 0.4562, Val Acc: 0.5384\n",
            "Epoch 163/199, Loss: 1.5023, Train Acc: 0.4555, Val Acc: 0.5384\n",
            "Epoch 164/199, Loss: 1.5067, Train Acc: 0.4537, Val Acc: 0.5384\n",
            "Epoch 165/199, Loss: 1.5059, Train Acc: 0.4520, Val Acc: 0.5384\n",
            "Epoch 166/199, Loss: 1.5066, Train Acc: 0.4545, Val Acc: 0.5384\n",
            "Epoch 167/199, Loss: 1.5072, Train Acc: 0.4543, Val Acc: 0.5384\n",
            "Epoch 168/199, Loss: 1.5051, Train Acc: 0.4544, Val Acc: 0.5384\n",
            "Epoch 169/199, Loss: 1.5068, Train Acc: 0.4539, Val Acc: 0.5384\n",
            "Epoch 170/199, Loss: 1.5069, Train Acc: 0.4549, Val Acc: 0.5384\n",
            "Epoch 171/199, Loss: 1.5035, Train Acc: 0.4550, Val Acc: 0.5384\n",
            "Epoch 172/199, Loss: 1.5046, Train Acc: 0.4539, Val Acc: 0.5384\n",
            "Epoch 173/199, Loss: 1.5024, Train Acc: 0.4552, Val Acc: 0.5384\n",
            "Epoch 174/199, Loss: 1.5037, Train Acc: 0.4525, Val Acc: 0.5384\n",
            "Epoch 175/199, Loss: 1.5041, Train Acc: 0.4539, Val Acc: 0.5384\n",
            "Epoch 176/199, Loss: 1.5059, Train Acc: 0.4541, Val Acc: 0.5384\n",
            "Epoch 177/199, Loss: 1.5017, Train Acc: 0.4554, Val Acc: 0.5384\n",
            "Epoch 178/199, Loss: 1.5043, Train Acc: 0.4538, Val Acc: 0.5384\n",
            "Epoch 179/199, Loss: 1.5084, Train Acc: 0.4542, Val Acc: 0.5384\n",
            "Epoch 180/199, Loss: 1.5063, Train Acc: 0.4537, Val Acc: 0.5384\n",
            "Epoch 181/199, Loss: 1.5073, Train Acc: 0.4524, Val Acc: 0.5384\n",
            "Epoch 182/199, Loss: 1.5022, Train Acc: 0.4561, Val Acc: 0.5384\n",
            "Epoch 183/199, Loss: 1.5020, Train Acc: 0.4563, Val Acc: 0.5384\n",
            "Epoch 184/199, Loss: 1.5054, Train Acc: 0.4554, Val Acc: 0.5384\n",
            "Epoch 185/199, Loss: 1.5087, Train Acc: 0.4505, Val Acc: 0.5384\n",
            "Epoch 186/199, Loss: 1.5060, Train Acc: 0.4536, Val Acc: 0.5384\n",
            "Epoch 187/199, Loss: 1.5054, Train Acc: 0.4570, Val Acc: 0.5384\n",
            "Epoch 188/199, Loss: 1.5068, Train Acc: 0.4532, Val Acc: 0.5384\n",
            "Epoch 189/199, Loss: 1.5053, Train Acc: 0.4541, Val Acc: 0.5384\n",
            "Epoch 190/199, Loss: 1.5025, Train Acc: 0.4543, Val Acc: 0.5384\n",
            "Epoch 191/199, Loss: 1.5034, Train Acc: 0.4566, Val Acc: 0.5384\n",
            "Epoch 192/199, Loss: 1.5060, Train Acc: 0.4529, Val Acc: 0.5384\n",
            "Epoch 193/199, Loss: 1.5030, Train Acc: 0.4532, Val Acc: 0.5384\n",
            "Epoch 194/199, Loss: 1.5052, Train Acc: 0.4532, Val Acc: 0.5384\n",
            "Epoch 195/199, Loss: 1.5067, Train Acc: 0.4521, Val Acc: 0.5384\n",
            "Epoch 196/199, Loss: 1.5015, Train Acc: 0.4538, Val Acc: 0.5384\n",
            "Epoch 197/199, Loss: 1.5015, Train Acc: 0.4551, Val Acc: 0.5384\n",
            "Epoch 198/199, Loss: 1.5039, Train Acc: 0.4553, Val Acc: 0.5384\n",
            "Epoch 199/199, Loss: 1.5091, Train Acc: 0.4522, Val Acc: 0.5384\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import numpy as np\n",
        "from torchvision.transforms import Lambda\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define AlexNet adapted for CIFAR-10/CIFAR-100\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(64, 192, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "\n",
        "        self.avg_pooling = torch.nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avg_pooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# PCA Color Augmentation\n",
        "def pca_color_augmentation(image):\n",
        "    reshaped_image = image.reshape(-1, 3).astype(np.float32)\n",
        "    mean = np.mean(reshaped_image, axis=0)\n",
        "    std = np.std(reshaped_image, axis=0)\n",
        "\n",
        "    # Avoid division by zero\n",
        "    std[std == 0] = 1\n",
        "\n",
        "    normalized_image = (reshaped_image - mean) / std\n",
        "\n",
        "    cov_matrix = np.cov(normalized_image, rowvar=False)\n",
        "\n",
        "    # Add a small value to the diagonal for numerical stability\n",
        "    cov_matrix += np.eye(cov_matrix.shape[0]) * 1e-5\n",
        "\n",
        "    eigenvalues, eigenvectors = np.linalg.eigh(cov_matrix)\n",
        "    sorted_indices = np.argsort(eigenvalues)[::-1]\n",
        "    eigenvectors = eigenvectors[:, sorted_indices]\n",
        "    eigenvalues = eigenvalues[sorted_indices]\n",
        "\n",
        "    alphas = np.random.normal(0, 0.1, 3)\n",
        "    pca_jitter = np.dot(eigenvectors, alphas * eigenvalues)\n",
        "    pca_jitter = (pca_jitter * std + mean).astype(np.float32)\n",
        "    augmented_image = normalized_image + pca_jitter\n",
        "    augmented_image = (augmented_image * std + mean).astype(np.uint8)\n",
        "\n",
        "    return augmented_image.reshape(image.shape)\n",
        "\n",
        "# Transforms including PCA color augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4), #40x40 pixels before the crop.\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    Lambda(lambda x: torch.tensor(pca_color_augmentation(x.numpy().transpose((1, 2, 0))), dtype=torch.float32).permute(2, 0, 1)),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_transforms = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 or CIFAR-100\n",
        "def get_dataloaders(dataset='CIFAR10', batch_size=128):\n",
        "    if dataset == 'CIFAR10':\n",
        "        train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=train_transforms)\n",
        "        test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=test_transforms)\n",
        "        num_classes = 10\n",
        "    elif dataset == 'CIFAR100':\n",
        "        train_dataset = datasets.CIFAR100(root='./data', train=True, download=True, transform=train_transforms)\n",
        "        test_dataset = datasets.CIFAR100(root='./data', train=False, download=True, transform=test_transforms)\n",
        "        num_classes = 100\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return train_loader, test_loader, num_classes\n",
        "\n",
        "# Training function\n",
        "def train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=25, device='cuda'):\n",
        "    model.to(device)\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # Lists for storing metrics\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        for inputs, labels in train_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(train_loader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n",
        "\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc.item())\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_running_corrects = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in test_loader:\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                val_running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        val_acc = val_running_corrects.double() / len(test_loader.dataset)\n",
        "        val_accuracies.append(val_acc.item())\n",
        "\n",
        "        print(f'Epoch {epoch}/{num_epochs-1}, Loss: {epoch_loss:.4f}, Train Acc: {epoch_acc:.4f}, Val Acc: {val_acc:.4f}')\n",
        "\n",
        "        # Step the scheduler\n",
        "        scheduler.step(val_acc)\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    # Plotting training metrics\n",
        "    epochs = range(num_epochs)\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    # Plot training loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, label='Training loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracies\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define dataset and dataloaders\n",
        "train_loader, test_loader, num_classes = get_dataloaders(dataset='CIFAR10', batch_size=128)\n",
        "\n",
        "# Initialize model, loss function, optimizer, and scheduler\n",
        "model = AlexNet(num_classes=num_classes)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=10, verbose=True, eps=1e-8)\n",
        "\n",
        "# Train the model\n",
        "trained_model = train_model(model, train_loader, test_loader, criterion, optimizer, scheduler, num_epochs=200)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "huX7pbB1ywrc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYnnAip9ywrc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlG-3jckywrc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvj7nRb7ywrc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:19:46.455807Z",
          "iopub.status.busy": "2024-06-10T18:19:46.45544Z",
          "iopub.status.idle": "2024-06-10T18:19:46.461671Z",
          "shell.execute_reply": "2024-06-10T18:19:46.460588Z",
          "shell.execute_reply.started": "2024-06-10T18:19:46.455772Z"
        },
        "id": "Kmd-STV9ywrc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:19:50.343088Z",
          "iopub.status.busy": "2024-06-10T18:19:50.342736Z",
          "iopub.status.idle": "2024-06-10T18:19:50.355028Z",
          "shell.execute_reply": "2024-06-10T18:19:50.354012Z",
          "shell.execute_reply.started": "2024-06-10T18:19:50.343061Z"
        },
        "id": "GcvX5VQrywrc",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),  # LRN layer\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=1e-4, beta=0.75, k=2.0),  # LRN layer\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "\n",
        "        # Typically, avgpooling is not used in the original AlexNet implementation\n",
        "        # but added for flexibility with different input sizes\n",
        "        self.avgpooling = nn.AdaptiveAvgPool2d((6, 6))  # Not originally in AlexNet\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = self.avgpooling(x)  # If using adaptive average pooling\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Example instantiation\n",
        "# model = AlexNet(num_classes=1000)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YXH_aigywrd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1hT-tZEywrd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZm8pDbAywrd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:27.690024Z",
          "iopub.status.busy": "2024-06-10T18:03:27.689673Z",
          "iopub.status.idle": "2024-06-10T18:03:32.046961Z",
          "shell.execute_reply": "2024-06-10T18:03:32.046188Z",
          "shell.execute_reply.started": "2024-06-10T18:03:27.689994Z"
        },
        "id": "SnLgmRhWywrd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:33.244851Z",
          "iopub.status.busy": "2024-06-10T18:03:33.24275Z",
          "iopub.status.idle": "2024-06-10T18:03:33.257395Z",
          "shell.execute_reply": "2024-06-10T18:03:33.256274Z",
          "shell.execute_reply.started": "2024-06-10T18:03:33.244813Z"
        },
        "id": "N8VJFTMHywrd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features_Extracter = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "\n",
        "            nn.Conv2d(96, 256, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "\n",
        "\n",
        "            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2), ###image dim=6*6\n",
        "\n",
        "\n",
        "        )\n",
        "        self.avgpooling = torch.nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features_Extracter(x)\n",
        "        x = self.avgpooling(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:34.641346Z",
          "iopub.status.busy": "2024-06-10T18:03:34.640674Z",
          "iopub.status.idle": "2024-06-10T18:03:34.650331Z",
          "shell.execute_reply": "2024-06-10T18:03:34.649329Z",
          "shell.execute_reply.started": "2024-06-10T18:03:34.641317Z"
        },
        "id": "lFdnmXlRywrd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def compute_pca_components(trainset):\n",
        "    data = np.concatenate([np.asarray(trainset[i][0]) for i in range(len(trainset))], axis=2)\n",
        "    data = data.reshape(-1, 3)  # Flatten the image pixels\n",
        "    mean = np.mean(data, axis=0)\n",
        "    data -= mean\n",
        "    cov = np.cov(data, rowvar=False)\n",
        "    eigvals, eigvecs = np.linalg.eigh(cov)\n",
        "    return eigvals, eigvecs, mean\n",
        "\n",
        "class PCATransform:\n",
        "    def __init__(self, eigvals, eigvecs, mean, alpha_std=0.1):\n",
        "        self.eigvals = eigvals\n",
        "        self.eigvecs = eigvecs\n",
        "        self.mean = mean\n",
        "        self.alpha_std = alpha_std\n",
        "\n",
        "    def __call__(self, img):\n",
        "        img = np.asarray(img).astype('float32')\n",
        "        img = img - self.mean\n",
        "        alpha = np.random.normal(0, self.alpha_std, size=3)\n",
        "        delta = np.dot(self.eigvecs, self.eigvals * alpha)\n",
        "        img = img + delta\n",
        "        img = img + self.mean\n",
        "        img = np.clip(img, 0, 255)\n",
        "        return torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:36.881335Z",
          "iopub.status.busy": "2024-06-10T18:03:36.880955Z",
          "iopub.status.idle": "2024-06-10T18:03:36.885692Z",
          "shell.execute_reply": "2024-06-10T18:03:36.884769Z",
          "shell.execute_reply.started": "2024-06-10T18:03:36.881305Z"
        },
        "id": "Ig5V8IN7ywrd",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:37.684129Z",
          "iopub.status.busy": "2024-06-10T18:03:37.683314Z",
          "iopub.status.idle": "2024-06-10T18:03:37.693152Z",
          "shell.execute_reply": "2024-06-10T18:03:37.692236Z",
          "shell.execute_reply.started": "2024-06-10T18:03:37.6841Z"
        },
        "id": "ysJX5GhLywre",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_dataloader(dataset='CIFAR10', batch_size=128, train=True, transform=None):\n",
        "    if transform is None:\n",
        "        if train:\n",
        "            transform_list = [\n",
        "                transforms.Resize(227),  # To ensure that it doesn't get smaller than 6x6\n",
        "                transforms.RandomCrop(32, padding=4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ]\n",
        "        else:\n",
        "            transform_list = [\n",
        "                transforms.ToTensor(),\n",
        "                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "            ]\n",
        "        transform = transforms.Compose(transform_list)\n",
        "\n",
        "    if dataset == 'CIFAR10':\n",
        "        dataset_obj = datasets.CIFAR10(root='./data', train=train, download=True, transform=transform)\n",
        "    elif dataset == 'CIFAR100':\n",
        "        dataset_obj = datasets.CIFAR100(root='./data', train=train, download=True, transform=transform)\n",
        "    else:\n",
        "        raise ValueError('Dataset must be either CIFAR10 or CIFAR100')\n",
        "\n",
        "    if train:\n",
        "        eigvals, eigvecs, mean = compute_pca_components(dataset_obj)\n",
        "        pca_transform = PCATransform(eigvals, eigvecs, mean)\n",
        "        # Update the transform with PCA transform\n",
        "        transform.transforms.insert(3, pca_transform)  # Insert PCA transform after horizontal flip\n",
        "\n",
        "    dataloader = DataLoader(dataset_obj, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return dataloader\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:39.461721Z",
          "iopub.status.busy": "2024-06-10T18:03:39.460953Z",
          "iopub.status.idle": "2024-06-10T18:03:39.46722Z",
          "shell.execute_reply": "2024-06-10T18:03:39.465573Z",
          "shell.execute_reply.started": "2024-06-10T18:03:39.461689Z"
        },
        "id": "8lvfUfFpywre",
        "outputId": "a3886a46-cfa2-4d71-d438-034d0e838b37",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "done?\n"
          ]
        }
      ],
      "source": [
        "print(\"done?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:40.429006Z",
          "iopub.status.busy": "2024-06-10T18:03:40.428136Z",
          "iopub.status.idle": "2024-06-10T18:03:40.438416Z",
          "shell.execute_reply": "2024-06-10T18:03:40.437453Z",
          "shell.execute_reply.started": "2024-06-10T18:03:40.428975Z"
        },
        "id": "xWzzYf0dywre",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * inputs.size(0) #contribution for each single batch in the epoch\n",
        "\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    return epoch_loss\n",
        "\n",
        "def evaluate(model, val_loader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    epoch_loss = running_loss / len(val_loader.dataset)\n",
        "    accuracy = 100. * correct / total\n",
        "    return epoch_loss, accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-06-10T18:03:41.422798Z",
          "iopub.status.busy": "2024-06-10T18:03:41.421881Z",
          "iopub.status.idle": "2024-06-10T18:04:53.249671Z",
          "shell.execute_reply": "2024-06-10T18:04:53.248033Z",
          "shell.execute_reply.started": "2024-06-10T18:03:41.422767Z"
        },
        "id": "c5SCf8IZywre",
        "outputId": "00068ba7-27cc-4792-83e3-9557f0a24c12",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170498071/170498071 [00:09<00:00, 17940861.33it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n    img = self.transform(img)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n    return F.to_tensor(pic)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 140, in to_tensor\n    raise TypeError(f\"pic should be PIL Image or ndarray. Got {type(pic)}\")\nTypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 21\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m               \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[8], line 14\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[0;32m---> 14\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     val_loss, val_accuracy \u001b[38;5;241m=\u001b[39m evaluate(model, val_loader, criterion, device)\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Train Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     18\u001b[0m           \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[7], line 4\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, criterion, optimizer, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[1;32m      5\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1345\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1371\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1371\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_utils.py:694\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    691\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    692\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
            "\u001b[0;31mTypeError\u001b[0m: Caught TypeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/datasets/cifar.py\", line 118, in __getitem__\n    img = self.transform(img)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 95, in __call__\n    img = t(img)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/transforms.py\", line 137, in __call__\n    return F.to_tensor(pic)\n  File \"/opt/conda/lib/python3.10/site-packages/torchvision/transforms/functional.py\", line 140, in to_tensor\n    raise TypeError(f\"pic should be PIL Image or ndarray. Got {type(pic)}\")\nTypeError: pic should be PIL Image or ndarray. Got <class 'torch.Tensor'>\n"
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    num_classes = 10  # Change to 100 for CIFAR-100\n",
        "    model = AlexNet(num_classes=num_classes).to(device)\n",
        "\n",
        "    train_loader = get_dataloader(dataset='CIFAR10', batch_size=128, train=True)\n",
        "    val_loader = get_dataloader(dataset='CIFAR10', batch_size=128, train=False)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "    num_epochs = 25\n",
        "    for epoch in range(num_epochs):\n",
        "        train_loss = train(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_accuracy = evaluate(model, val_loader, criterion, device)\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, '\n",
        "              f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kk1Md0AZywre"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "AlexNet Implementation",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
